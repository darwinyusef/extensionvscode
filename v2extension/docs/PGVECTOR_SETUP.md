# üîç pgvector Setup - Vector Search para RAG

## ¬øQu√© es pgvector?

**pgvector** es una extensi√≥n de PostgreSQL que permite almacenar y buscar vectores (embeddings) directamente en la base de datos.

### Ventajas

- ‚úÖ **Integrado con PostgreSQL** - No necesitas base de datos separada
- ‚úÖ **HNSW Index** - B√∫squeda vectorial en O(log n)
- ‚úÖ **Escalable** - Millones de vectores sin problemas
- ‚úÖ **Compatible con OpenAI** - Soporta embeddings de 1536 dims
- ‚úÖ **Operadores de similitud** - Cosine, L2, Inner product

---

## üìã Instalaci√≥n

### macOS (Homebrew)

```bash
# Instalar pgvector
brew install pgvector

# O si ya tienes PostgreSQL instalado:
brew tap pgvector/tap
brew install pgvector
```

### Linux (Ubuntu/Debian)

```bash
# Instalar dependencias
sudo apt update
sudo apt install -y postgresql-server-dev-15 build-essential git

# Clonar repositorio
cd /tmp
git clone --branch v0.5.1 https://github.com/pgvector/pgvector.git
cd pgvector

# Compilar e instalar
make
sudo make install
```

### Linux (usando paquete)

```bash
# PostgreSQL 15
sudo apt install postgresql-15-pgvector

# PostgreSQL 14
sudo apt install postgresql-14-pgvector
```

### Docker

```yaml
# docker-compose.yml
services:
  postgres:
    image: pgvector/pgvector:pg15
    environment:
      POSTGRES_USER: postgres
      POSTGRES_PASSWORD: postgres
      POSTGRES_DB: ai_goals_tracker
    ports:
      - "5432:5432"
    volumes:
      - postgres-data:/var/lib/postgresql/data
```

---

## üöÄ Habilitaci√≥n en Base de Datos

### 1. Conectar a PostgreSQL

```bash
psql -U postgres -d ai_goals_tracker
```

### 2. Crear la extensi√≥n

```sql
CREATE EXTENSION IF NOT EXISTS vector;
```

### 3. Verificar instalaci√≥n

```sql
-- Ver extensi√≥n instalada
SELECT * FROM pg_extension WHERE extname = 'vector';

-- Debe retornar:
--  oid  | extname | extowner | extnamespace | extrelocatable | extversion
-- ------+---------+----------+--------------+----------------+------------
-- 16389 | vector  |       10 |         2200 | t              | 0.5.1
```

---

## üìä Uso en el Proyecto

### Modelo con pgvector

```python
# backend/app/models/embedding.py

from pgvector.sqlalchemy import Vector
from sqlalchemy.orm import Mapped, mapped_column

class Embedding(Base):
    __tablename__ = "embeddings"

    # Vector de 1536 dimensiones (OpenAI text-embedding-3-small)
    embedding: Mapped[Vector] = mapped_column(Vector(1536), nullable=False)
```

### Crear Tabla

```sql
-- Migraci√≥n 007: create_embeddings_table.py

CREATE TABLE embeddings (
    id VARCHAR(36) PRIMARY KEY,
    user_id VARCHAR(36) NOT NULL,
    entity_type VARCHAR(50) NOT NULL,
    entity_id VARCHAR(36) NOT NULL,
    content TEXT NOT NULL,
    embedding vector(1536) NOT NULL,  -- ‚≠ê pgvector column
    model VARCHAR(100) NOT NULL,
    metadata JSONB,
    created_at TIMESTAMP NOT NULL
);
```

### Crear √çndice HNSW

```sql
-- HNSW: Hierarchical Navigable Small World
-- B√∫squeda vectorial en O(log n) - MUY R√ÅPIDO

CREATE INDEX idx_embeddings_vector_hnsw
ON embeddings
USING hnsw (embedding vector_cosine_ops)
WITH (m = 16, ef_construction = 64);
```

**Par√°metros**:
- `m = 16` - N√∫mero de conexiones por nodo (default: 16)
- `ef_construction = 64` - Tama√±o de b√∫squeda al construir (default: 64)
- Valores m√°s altos = mejor accuracy, m√°s lento

### Alternativa: IVFFlat Index

```sql
-- IVFFlat: Inverted File with Flat Compression
-- Construcci√≥n m√°s r√°pida, b√∫squeda m√°s lenta

CREATE INDEX idx_embeddings_vector_ivfflat
ON embeddings
USING ivfflat (embedding vector_cosine_ops)
WITH (lists = 100);
```

**Cu√°ndo usar**:
- HNSW: Mejor para producci√≥n (b√∫squeda m√°s r√°pida)
- IVFFlat: Mejor para desarrollo (construcci√≥n m√°s r√°pida)

---

## üîç B√∫squeda de Similitud

### Operadores de Distancia

| Operador | Significado | Uso |
|----------|-------------|-----|
| `<->` | L2 distance | Distancia euclidiana |
| `<#>` | Inner product | Producto interno negativo |
| `<=>` | Cosine distance | Distancia de coseno (recomendado) |

### Query de Similitud

```sql
-- Buscar los 5 vectores m√°s similares
SELECT
    id,
    content,
    1 - (embedding <=> :query_embedding) as similarity
FROM embeddings
WHERE user_id = :user_id
ORDER BY embedding <=> :query_embedding
LIMIT 5;
```

**Nota**: Menor distancia = Mayor similitud
- `similarity = 1 - distance`
- Similarity de 1.0 = Id√©ntico
- Similarity de 0.0 = Totalmente diferente

---

## üìà Performance y Optimizaci√≥n

### Tama√±o de √çndice

```sql
-- Ver tama√±o del √≠ndice HNSW
SELECT
    schemaname,
    tablename,
    indexname,
    pg_size_pretty(pg_relation_size(indexrelid)) as index_size
FROM pg_stat_user_indexes
WHERE indexname = 'idx_embeddings_vector_hnsw';
```

### Estad√≠sticas de Uso

```sql
-- Ver cu√°ntas b√∫squedas usa el √≠ndice
SELECT
    schemaname,
    tablename,
    indexname,
    idx_scan as index_scans,
    idx_tup_read as tuples_read,
    idx_tup_fetch as tuples_fetched
FROM pg_stat_user_indexes
WHERE indexname = 'idx_embeddings_vector_hnsw';
```

### Tuning HNSW

Para mejor accuracy (m√°s lento):
```sql
-- Aumentar par√°metros
CREATE INDEX ... WITH (m = 32, ef_construction = 128);
```

Para mejor velocidad (menos accuracy):
```sql
-- Reducir par√°metros
CREATE INDEX ... WITH (m = 8, ef_construction = 32);
```

---

## üéØ Ejemplo Completo con OpenAI

### 1. Generar Embedding

```python
from openai import AsyncOpenAI

client = AsyncOpenAI()

async def generate_embedding(text: str) -> list[float]:
    """Generar embedding con OpenAI."""
    response = await client.embeddings.create(
        model="text-embedding-3-small",
        input=text
    )
    return response.data[0].embedding
```

### 2. Guardar en Base de Datos

```python
from app.models import Embedding
from app.core.database import AsyncSessionLocal

async def save_embedding(
    user_id: str,
    entity_type: str,
    entity_id: str,
    content: str
):
    """Guardar embedding en PostgreSQL."""

    # Generar embedding
    embedding_vector = await generate_embedding(content)

    # Guardar en DB
    async with AsyncSessionLocal() as db:
        embedding = Embedding(
            id=str(uuid.uuid4()),
            user_id=user_id,
            entity_type=entity_type,
            entity_id=entity_id,
            content=content,
            embedding=embedding_vector,  # pgvector!
            model="text-embedding-3-small"
        )

        db.add(embedding)
        await db.commit()
```

### 3. Buscar Similares

```python
from sqlalchemy import text

async def search_similar(query: str, user_id: str, limit: int = 5):
    """Buscar embeddings similares usando pgvector."""

    # Generar embedding de la query
    query_embedding = await generate_embedding(query)

    # Buscar con pgvector
    async with AsyncSessionLocal() as db:
        sql = text("""
            SELECT
                id,
                entity_type,
                content,
                1 - (embedding <=> :embedding) as similarity
            FROM embeddings
            WHERE user_id = :user_id
            ORDER BY embedding <=> :embedding
            LIMIT :limit
        """)

        result = await db.execute(
            sql,
            {
                "embedding": str(query_embedding),
                "user_id": user_id,
                "limit": limit
            }
        )

        return result.fetchall()
```

---

## üß™ Testing pgvector

### Test Manual

```sql
-- 1. Insertar vector de prueba
INSERT INTO embeddings (
    id, user_id, entity_type, entity_id, content, embedding, model
) VALUES (
    'test-001',
    'user-123',
    'test',
    'test-001',
    'Hello world',
    '[0.1, 0.2, 0.3, ...]',  -- 1536 valores
    'test-model'
);

-- 2. Buscar similares
SELECT
    id,
    content,
    embedding <=> '[0.1, 0.2, 0.3, ...]' as distance
FROM embeddings
ORDER BY embedding <=> '[0.1, 0.2, 0.3, ...]'
LIMIT 5;
```

### Test con Script Python

```python
# backend/scripts/test_pgvector.py

import asyncio
from app.core.database import AsyncSessionLocal
from app.models import Embedding
from sqlalchemy import text

async def test_pgvector():
    """Test pgvector functionality."""

    print("üîç Testing pgvector...")

    async with AsyncSessionLocal() as db:
        # Test 1: Ver si extensi√≥n est√° instalada
        result = await db.execute(
            text("SELECT extversion FROM pg_extension WHERE extname = 'vector'")
        )
        version = result.scalar()
        print(f"‚úÖ pgvector version: {version}")

        # Test 2: Contar embeddings
        result = await db.execute(text("SELECT COUNT(*) FROM embeddings"))
        count = result.scalar()
        print(f"‚úÖ Total embeddings: {count}")

        # Test 3: Verificar √≠ndice HNSW
        result = await db.execute(text("""
            SELECT indexname
            FROM pg_indexes
            WHERE tablename = 'embeddings'
            AND indexname LIKE '%hnsw%'
        """))
        index = result.scalar()
        print(f"‚úÖ HNSW index: {index or 'Not created yet'}")

if __name__ == "__main__":
    asyncio.run(test_pgvector())
```

---

## üîß Troubleshooting

### Error: "type vector does not exist"

```bash
# Extensi√≥n no instalada
psql -U postgres -d ai_goals_tracker -c "CREATE EXTENSION vector;"
```

### Error: "could not load library pgvector.so"

```bash
# Reinstalar pgvector
# macOS
brew reinstall pgvector

# Linux
sudo make install  # desde directorio pgvector
```

### Error: "index method hnsw does not exist"

```bash
# Versi√≥n de pgvector muy antigua
# Actualizar a v0.5.0+
```

### Performance Lento

```sql
-- 1. Ver si √≠ndice se usa
EXPLAIN ANALYZE
SELECT * FROM embeddings
ORDER BY embedding <=> '[...]'
LIMIT 5;

-- Debe mostrar: "Index Scan using idx_embeddings_vector_hnsw"

-- 2. Si no usa √≠ndice, recrear
DROP INDEX idx_embeddings_vector_hnsw;
CREATE INDEX idx_embeddings_vector_hnsw
ON embeddings USING hnsw (embedding vector_cosine_ops);

-- 3. Actualizar estad√≠sticas
ANALYZE embeddings;
```

---

## üìö Recursos

- **Documentaci√≥n Oficial**: https://github.com/pgvector/pgvector
- **Paper HNSW**: https://arxiv.org/abs/1603.09320
- **OpenAI Embeddings**: https://platform.openai.com/docs/guides/embeddings
- **pgvector + SQLAlchemy**: https://github.com/pgvector/pgvector-python

---

## ‚úÖ Checklist de Instalaci√≥n

- [ ] pgvector instalado en sistema
- [ ] Extensi√≥n habilitada: `CREATE EXTENSION vector;`
- [ ] Tabla embeddings creada (migraci√≥n 007)
- [ ] √çndice HNSW creado
- [ ] Test de b√∫squeda exitoso
- [ ] pyproject.toml tiene `pgvector`

---

## üì¶ Dependencias Python

Aseg√∫rate de tener en `pyproject.toml`:

```toml
[tool.poetry.dependencies]
pgvector = "^0.2.4"
psycopg2-binary = "^2.9.9"  # O psycopg (async)
sqlalchemy = "^2.0.23"
```

Instalar:
```bash
poetry add pgvector
```

---

**Versi√≥n pgvector**: 0.5.1+
**Dimensiones**: 1536 (OpenAI text-embedding-3-small)
**√çndice**: HNSW (Hierarchical Navigable Small World)
**Performance**: O(log n) b√∫squeda
**Estado**: ‚úÖ Listo para RAG en producci√≥n
